{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import linear_model\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "from sklearn import preprocessing\n",
    "import seaborn as sns\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.over_sampling import RandomOverSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data/temp_merged.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns=['Unnamed: 0', 'FlightDate', 'Quarter', 'Year', 'Month', 'DayofMonth',\n",
    "       'Origin', 'Dest','ArrTime'])\n",
    "y = df['ArrDel15']\n",
    "X = df.drop(columns=['ArrDel15','ArrDelayMinutes'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['DepTime', 'DepDel15', 'CRSDepTime', 'DepDelayMinutes',\n",
       "       'OriginAirportID', 'DestAirportID', 'CRSArrTime', 'windspeedKmph_x',\n",
       "       'DewPointF_x', 'cloudcover_x', 'precipMM_x', 'pressure_x',\n",
       "       'WindGustKmph_x', 'visibility_x', 'weatherCode_x', 'tempF_x',\n",
       "       'WindChillF_x', 'winddirDegree_x', 'humidity_x', 'windspeedKmph_y',\n",
       "       'DewPointF_y', 'cloudcover_y', 'precipMM_y', 'pressure_y',\n",
       "       'WindGustKmph_y', 'visibility_y', 'weatherCode_y', 'tempF_y',\n",
       "       'WindChillF_y', 'winddirDegree_y', 'humidity_y'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#FEATURE SET\n",
    "X.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SMOTE OVERSAMPLING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(X, y, train_size=0.7)\n",
    "sm = RandomOverSampler()\n",
    "x_train, y_train = sm.fit_sample(x_train, y_train)\n",
    "sampled_df = pd.concat([pd.DataFrame(x_train), pd.DataFrame(y_train)], axis=1)\n",
    "\n",
    "k=X.columns\n",
    "z=pd.DataFrame(y,columns=['ArrDel15'])\n",
    "sampled_df.columns=k.append(z.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled_df.ArrDel15.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using selectKBest to select best features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "Scaled_X = min_max_scaler.fit_transform(x_train)\n",
    "\n",
    "bestfeatures = SelectKBest(chi2, k=15)\n",
    "fit = bestfeatures.fit(Scaled_X,y_train)\n",
    "\n",
    "dfscores = pd.DataFrame(fit.scores_)\n",
    "dfcolumns = pd.DataFrame(X.columns)\n",
    "\n",
    "#concat two dataframes for better visualization \n",
    "featureScores = pd.concat([dfcolumns,dfscores],axis=1)\n",
    "featureScores.columns = ['Specs','Score']  \n",
    "feats = list(featureScores.nlargest(22,'Score').Specs)\n",
    "x_train = sampled_df[feats]\n",
    "x_test = x_test[feats]\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LOGISTIC REGRESSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = linear_model.LogisticRegression(max_iter=5000)\n",
    "clf = lr.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic regression Train Accuracy :  0.8543605145018521\n",
      "Logistic regression Test Accuracy  :  0.8961147219271556\n",
      "[[ 90438  25831]\n",
      " [ 31870 407291]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.94      0.93      0.93    439161\n",
      "         1.0       0.74      0.78      0.76    116269\n",
      "\n",
      "    accuracy                           0.90    555430\n",
      "   macro avg       0.84      0.85      0.85    555430\n",
      "weighted avg       0.90      0.90      0.90    555430\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Logistic regression Train Accuracy : \", clf.score(x_train,y_train))\n",
    "print(\"Logistic regression Test Accuracy  : \", metrics.accuracy_score(y_test, lr.predict(x_test)))\n",
    "\n",
    "print(confusion_matrix(y_test,lr.predict(x_test),labels=[1,0]))\n",
    "\n",
    "print(classification_report(y_test,lr.predict(x_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RANDOM FOREST CLASSIFIER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(criterion='entropy')\n",
    "clf = rf.fit(x_train, y_train)\n",
    "y_pred = rf.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Train Accuracy :  0.9999985354623155\n",
      " Test Accuracy  :  0.9153376663125866\n",
      "CONFUSION MATRIX\n",
      " [[ 85368  30901]\n",
      " [ 16123 423038]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.93      0.96      0.95    439161\n",
      "         1.0       0.84      0.73      0.78    116269\n",
      "\n",
      "    accuracy                           0.92    555430\n",
      "   macro avg       0.89      0.85      0.87    555430\n",
      "weighted avg       0.91      0.92      0.91    555430\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\" Train Accuracy : \", clf.score(x_train, y_train))\n",
    "print(\" Test Accuracy  : \", metrics.accuracy_score(y_test, y_pred))\n",
    "\n",
    "print(\"CONFUSION MATRIX\\n\",confusion_matrix(y_test, y_pred, labels=[1,0]))\n",
    "\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EXTRA TREES CLASSIFIER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "ex = ExtraTreesClassifier(criterion='entropy')\n",
    "clf = ex.fit(x_train,y_train)\n",
    "y_pred = ex.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Train Accuracy :  0.9999995118207718\n",
      " Test Accuracy  :  0.911209333309328\n",
      "CONFUSION MATRIX\n",
      " [[ 85914  30355]\n",
      " [ 18962 420199]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.93      0.96      0.94    439161\n",
      "         1.0       0.82      0.74      0.78    116269\n",
      "\n",
      "    accuracy                           0.91    555430\n",
      "   macro avg       0.88      0.85      0.86    555430\n",
      "weighted avg       0.91      0.91      0.91    555430\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\" Train Accuracy : \", clf.score(x_train,y_train))\n",
    "print(\" Test Accuracy  : \", metrics.accuracy_score(y_test, y_pred))\n",
    "\n",
    "print(\"CONFUSION MATRIX\\n\",confusion_matrix(y_test,y_pred,labels=[1,0]))\n",
    "\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  XGBOOST CLASSIFIER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "xg = XGBClassifier()\n",
    "clf = xg.fit(x_train, y_train)\n",
    "y_pred = xg.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Train Accuracy :  0.8684786577805029\n",
      " Test Accuracy  :  0.8964045874367607\n",
      "CONFUSION MATRIX\n",
      " [[ 93247  23022]\n",
      " [ 34518 404643]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.95      0.92      0.93    439161\n",
      "         1.0       0.73      0.80      0.76    116269\n",
      "\n",
      "    accuracy                           0.90    555430\n",
      "   macro avg       0.84      0.86      0.85    555430\n",
      "weighted avg       0.90      0.90      0.90    555430\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\" Train Accuracy : \", clf.score(x_train, y_train))\n",
    "print(\" Test Accuracy  : \", metrics.accuracy_score(y_test, y_pred))\n",
    "\n",
    "print(\"CONFUSION MATRIX\\n\",confusion_matrix(y_test, y_pred, labels=[1,0]))\n",
    "\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DECISON TREES CLASSIFIER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = DecisionTreeClassifier()\n",
    "clf = ds.fit(x_train, y_train)\n",
    "y_pred = ds.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Train Accuracy :  0.9999995118207718\n",
      " Test Accuracy  :  0.8718236321408638\n",
      "CONFUSION MATRIX\n",
      " [[ 80994  35275]\n",
      " [ 35918 403243]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.92      0.92      0.92    439161\n",
      "         1.0       0.69      0.70      0.69    116269\n",
      "\n",
      "    accuracy                           0.87    555430\n",
      "   macro avg       0.81      0.81      0.81    555430\n",
      "weighted avg       0.87      0.87      0.87    555430\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\" Train Accuracy : \", clf.score(x_train, y_train))\n",
    "print(\" Test Accuracy  : \", metrics.accuracy_score(y_test, y_pred))\n",
    "\n",
    "print(\"CONFUSION MATRIX\\n\",confusion_matrix(y_test, y_pred, labels=[1,0]))\n",
    "\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
